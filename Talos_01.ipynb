{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for a Deep Learning Regression Problem Using Talos\n",
    "\n",
    "First import the necessary moduldes, load and split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adamax, Adam, Nadam, Adadelta, Adagrad\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import talos\n",
    "from talos.utils import hidden_layers\n",
    "from talos.model.normalizers import lr_normalizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = \"/home/ubuntu/G/\"\n",
    "with open(path + \"01_Data\", \"rb\") as datafile:\n",
    "    data = pickle.load(datafile)\n",
    "    \n",
    "X_df_train = data[0]\n",
    "y_df_train = data[1]\n",
    "X_df_test = data[2]\n",
    "y_df_test = data[3]\n",
    "PredData = data[4]\n",
    "PredData1_binary = data[6]\n",
    "baseseed = data[8]\n",
    "\n",
    "datafile.close()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_df_train2, X_df_val, y_df_train2, y_df_val = train_test_split(X_df_train, y_df_train, test_size=0.33,\n",
    "                                                                  random_state=baseseed, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'optimizer': [Adamax, Nadam, Adagrad, Adadelta],\n",
    "     'first_neuron': [5120, 1024, 512, 128],\n",
    "     'batch_size': [100, 1000, 5000, 10000],\n",
    "     'epochs': [45],\n",
    "     'hidden_layers':[0, 1, 2, 3, 4],\n",
    "     'kernel_initializer': ['uniform', 'normal'],\n",
    "     'dropout': [0.0, 0.25, 0.5, 0.65, 2, 3, 4, 5, 10],\n",
    "     'losses': [\"mse\"],\n",
    "     'shapes': ['brick', 'triangle', 'funnel'],\n",
    "     'activation': ['relu'],\n",
    "     'lr': list(np.linspace(0, 1, 10))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model function. The model includes an eraly stopping and includes metrics and losses for a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcmodel(X_train, y_train, x_val, y_val, params):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    esr = 2\n",
    "    callbacks = [EarlyStopping(monitor=\"val_mean_absolute_error\", patience=esr, mode=\"min\", \n",
    "                               min_delta = 0.001, baseline=0.1)]\n",
    "    \n",
    "    model.add(Dense(params['first_neuron'], input_dim=X_train.shape[1],\n",
    "                    activation=\"relu\",\n",
    "                    kernel_initializer = params['kernel_initializer'] ))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    ## hidden layers\n",
    "    hidden_layers(model, params, 1)\n",
    "    \n",
    "    model.add(Dense(1, activation=\"sigmoid\",\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    model.compile(loss=params[\"losses\"], \n",
    "                  optimizer=params['optimizer'](lr_normalizer(params['lr'], \n",
    "                                                params['optimizer'])),\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        epochs=params['epochs'],\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=2)\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a name for the project and set the path for saving everything. Also setting the scan parameters. I chose 100 rounds, and the tree reduction method. Since it showed much better results than the random serach.\n",
    "For demo purposes I only included 1 round below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]WARNING: Logging before flag parsing goes to stderr.\n",
      "W1216 12:42:15.624506 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1216 12:42:15.642313 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1216 12:42:15.645228 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1216 12:42:15.660840 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1216 12:42:15.669661 140127182698240 deprecation.py:506] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1216 12:42:15.708017 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 100, 'dropout': 0.25, 'epochs': 45, 'first_neuron': 512, 'hidden_layers': 0, 'kernel_initializer': 'uniform', 'losses': 'mse', 'lr': 0.3333333333333333, 'optimizer': <class 'keras.optimizers.Adagrad'>, 'shapes': 'triangle'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1216 12:42:15.952292 140127182698240 deprecation_wrapper.py:119] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 597956 samples, validate on 294516 samples\n",
      "Epoch 1/45\n",
      " - 16s - loss: 0.0190 - mean_absolute_error: 0.0849 - val_loss: 0.0172 - val_mean_absolute_error: 0.0780\n",
      "Epoch 2/45\n",
      " - 15s - loss: 0.0167 - mean_absolute_error: 0.0772 - val_loss: 0.0162 - val_mean_absolute_error: 0.0744\n",
      "Epoch 3/45\n",
      " - 15s - loss: 0.0159 - mean_absolute_error: 0.0748 - val_loss: 0.0155 - val_mean_absolute_error: 0.0733\n",
      "Epoch 4/45\n",
      " - 15s - loss: 0.0154 - mean_absolute_error: 0.0733 - val_loss: 0.0151 - val_mean_absolute_error: 0.0717\n",
      "Epoch 5/45\n",
      " - 15s - loss: 0.0151 - mean_absolute_error: 0.0722 - val_loss: 0.0148 - val_mean_absolute_error: 0.0710\n",
      "Epoch 6/45\n",
      " - 15s - loss: 0.0148 - mean_absolute_error: 0.0713 - val_loss: 0.0145 - val_mean_absolute_error: 0.0707\n",
      "Epoch 7/45\n",
      " - 15s - loss: 0.0145 - mean_absolute_error: 0.0706 - val_loss: 0.0143 - val_mean_absolute_error: 0.0697\n",
      "Epoch 8/45\n",
      " - 15s - loss: 0.0144 - mean_absolute_error: 0.0701 - val_loss: 0.0141 - val_mean_absolute_error: 0.0690\n",
      "Epoch 9/45\n",
      " - 15s - loss: 0.0142 - mean_absolute_error: 0.0695 - val_loss: 0.0139 - val_mean_absolute_error: 0.0692\n",
      "Epoch 10/45\n",
      " - 15s - loss: 0.0140 - mean_absolute_error: 0.0691 - val_loss: 0.0138 - val_mean_absolute_error: 0.0678\n",
      "Epoch 11/45\n",
      " - 15s - loss: 0.0139 - mean_absolute_error: 0.0687 - val_loss: 0.0137 - val_mean_absolute_error: 0.0675\n",
      "Epoch 12/45\n",
      " - 15s - loss: 0.0138 - mean_absolute_error: 0.0683 - val_loss: 0.0136 - val_mean_absolute_error: 0.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:58<00:00, 178.15s/it]\n"
     ]
    }
   ],
   "source": [
    "proj = \"Test01\"\n",
    "path2 = path + \"LeNA_2/TalosTest/\" + proj + \"/\"\n",
    "\n",
    "if os.path.exists(path2):\n",
    "    shutil.rmtree(path2)\n",
    "\n",
    "t = talos.Scan(x=X_df_train2.values,\n",
    "            y=y_df_train2.values,\n",
    "            model=fcmodel,\n",
    "            params=p,\n",
    "            x_val=X_df_val.values,\n",
    "            y_val=y_df_val.values,\n",
    "            seed=baseseed,\n",
    "            experiment_name=proj,\n",
    "            print_params=True,\n",
    "            round_limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the analysis dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anafilename = os.listdir(path2)[0]\n",
    "anafile = path2 + anafilename\n",
    "r = talos.Reporting(anafile)\n",
    "\n",
    "and_df = r.data\n",
    "anadf = r.data.sort_values(\"val_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the project for later usage of the model. Then evaluatiob takes place. In the live version I got an mae of approx. 0.029, which is pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package Test01_dep have been saved.\n",
      "[0.06487381557437902, 0.0659965060772302, 0.06566398204058764, 0.06538066394994979, 0.06628905642157068]\n"
     ]
    }
   ],
   "source": [
    "path3 = path + \"LeNA_2/TalosTest/\"\n",
    "\n",
    "if os.path.exists(path3 + proj + \"_dep-zip\"):\n",
    "    os.remove(path3 + proj + \"_dep-zip\")\n",
    "\n",
    "td = talos.Deploy(t, proj + \"_dep\", metric=\"val_mean_absolute_error\", asc=True)\n",
    "\n",
    "path_dep = path + \"LeNA_2/TalosTest/\"\n",
    "talosfileslist = os.listdir(path_dep)\n",
    "talosfileslist = [x for x in talosfileslist if x.find(proj + \"_dep.zip\") != -1]\n",
    "talosfile = talosfileslist[0]\n",
    "\n",
    "tr = talos.Restore(talosfile)\n",
    "\n",
    "e = talos.Evaluate(t)\n",
    "\n",
    "a = e.evaluate(X_df_test.values, y_df_test.values, metric=\"mae\",\n",
    "           task=\"continuous\", folds=5, model_id=anadf.val_mean_absolute_error.idxmin())\n",
    "\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
